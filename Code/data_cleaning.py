import pandas as pd
from sklearn.preprocessing import MinMaxScaler

def clean_data(input_file, output_file):
    """
    Cleans the stock market data by handling missing values and normalizing the data.

    Args:
        input_file (str): Path to the input CSV file.
        output_file (str): Path to the output CSV file.
    """
    try:
        # Load data
        data = pd.read_csv(input_file)
        print("Data loaded successfully.")
        
        # Convert relevant columns to numeric, coercing errors to NaN
        cols = ["price", "close", "high", "low", "open", "volume"]
        data[cols] = data[cols].apply(pd.to_numeric, errors="coerce")
        print("Converted relevant columns to numeric.")

        # Print data types to debug
        print(data.dtypes)
        
        # Handle NaN values in the price column specifically
        if data["price"].isna().sum() > 0:
            print("Handling NaN values in the price column.")
            data["price"].fillna(data["price"].mean(), inplace=True)

        # Select numeric columns
        numeric_data = data.select_dtypes(include="number")
        print("Selected numeric columns.")
        
        # Fill missing values with the mean for other columns
        numeric_data.fillna(numeric_data.mean(), inplace=True)
        print("Missing values filled.")
        
        # Normalize data using Min-Max Scaling
        scaler = MinMaxScaler()
        data_scaled = pd.DataFrame(scaler.fit_transform(numeric_data), columns=numeric_data.columns)
        print("Data normalized.")
        
        # Save cleaned data
        data_scaled.to_csv(output_file, index=False)
        print(f"Cleaned data saved to {output_file}")
    except Exception as e:
        print(f"Error cleaning data: {str(e)}")  # Ensure error message is a string

if __name__ == "__main__":
    clean_data("C:/Projects/Simplified_Stock_Market_Predictor_AI/MarketMind-AI/Data/fixed_stock_data.csv", 
               "C:/Projects/Simplified_Stock_Market_Predictor_AI/MarketMind-AI/Data/cleaned_stock_data.csv")

# Generated by Nicole LeGuern